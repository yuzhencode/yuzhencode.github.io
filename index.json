


[{"content":"Recently, I encountered an interesting SQL challenge. The task required using window functions to analyze employee salaries within departments. This is a powerful yet sometimes tricky feature in SQL.\nHere is the problem description and how I solved it.\nProblem Description # sql dept salary ranking\nIn this MySQL challenge, your task is to analyze salary rankings within each company department. Construct a query that accomplishes the following objectives:\nIndividual Salary Rankings: For each department represented by \u0026lsquo;DivisionID\u0026rsquo;, rank the employees based on their salaries in descending order. Salary Comparisons: Calculate the difference in salary (SalaryDifference) between each employee and the next lower-paid employee in the same department. For the lowest-paid employee in each department, the \u0026lsquo;SalaryDifference should be displayed as \u0026lsquo;NULL. Highlight Top Earners: Include a column titled \u0026lsquo;IsTopEarner\u0026rsquo; that displays \u0026ldquo;Yes\u0026rdquo; for the highest-paid employee in each department and \u0026ldquo;No\u0026rdquo; for all other employees. ID Name DivisionID ManagerID Salary 356 Daniel Smith 100 133 40000 122 Arnold Sully 101 null 60000 467 Lisa Roberts 100 null 80000 112 Mary Dial 105 467 65000 775 Dennis Front 103 null 90000 111 Larry Weis 104 35534 75000 222 Mark Red 102 133 86000 577 Robert Night 105 12353 76000 133 Susan Wall 105 577 110000 Notice:\nTable name: Employees MySQL version: 5.5.56-log The result should include the following columns (ordered by SalaryRank in ascending order): DivisionID（ID of the department) Name (Name of the employee) Salary (Salary of the employee) SalaryRank（(Rank of the employee\u0026rsquo;s salary within the department, with 1 being the highest salary) SalaryDifference (Difference in salary between the employee and the next lower-paid employee in the same department) IsTopEarner（Indicates if the employee is the top earner in their department) -- Create the table CREATE TABLE Employees ( ID INT PRIMARY KEY, Name VARCHAR(100), DivisionID INT, ManagerID INT, Salary DECIMAL(10, 2) ); -- Insert data into the Employees table INSERT INTO Employees (ID, Name, DivisionID, ManagerID, Salary) VALUES (356, \u0026#39;Daniel Smith\u0026#39;, 100, 133, 40000), (122, \u0026#39;Arnold Sully\u0026#39;, 101, NULL, 60000), (467, \u0026#39;Lisa Roberts\u0026#39;, 100, NULL, 80000), (112, \u0026#39;Mary Dial\u0026#39;, 105, 467, 65000), (775, \u0026#39;Dennis Front\u0026#39;, 103, NULL, 90000), (111, \u0026#39;Larry Weis\u0026#39;, 104, 35534, 75000), (222, \u0026#39;Mark Red\u0026#39;, 102, 133, 86000), (577, \u0026#39;Robert Night\u0026#39;, 105, 12353, 76000), (133, \u0026#39;Susan Wall\u0026#39;, 105, 577, 110000); Solution \u0026amp; Analysis # 1. Analyze the Problem # This is a typical application of SQL window functions, which involves:\nGrouping the data by department (PARTITION BY DivisionID). Ranking rows based on a specific condition (RANK() or ROW_NUMBER()). Comparing the current row to adjacent rows (LEAD()). Identifying the first row in each group (FIRST_VALUE() or using conditional logic). 2. Writing the Query # Here is the complete query that satisfies the requirements:\nSELECT DivisionID, Name, Salary, ROW_NUMBER() OVER (PARTITION BY DivisionID ORDER BY Salary DESC) AS SalaryRank, Salary - LEAD(Salary) OVER (PARTITION BY DivisionID ORDER BY Salary DESC) AS SalaryDifference, CASE WHEN RANK() OVER (PARTITION BY DivisionID ORDER BY Salary DESC) = 1 THEN \u0026#39;Yes\u0026#39; ELSE \u0026#39;No\u0026#39; END AS IsTopEarner FROM Employees ORDER BY DivisionID, SalaryRank; 3. Query Explanation # Salary Ranking We use RANK() or ROW_NUMBER() to rank employees by salary within each department (PARTITION BY DivisionID), ordered by salary in descending order: RANK() OVER (PARTITION BY DivisionID ORDER BY Salary DESC) AS SalaryRank # or ROW_NUMBER() OVER (PARTITION BY DivisionID ORDER BY Salary DESC) AS SalaryRank Salary Difference Calculation The LEAD() function retrieves the salary of the next row (lower-paid employee) within the same department (PARTITION BY DivisionID), and calculates the difference between the current and next employee\u0026rsquo;s salary: Salary - LEAD(Salary) OVER (PARTITION BY DivisionID ORDER BY Salary DESC) AS SalaryDifference, For the lowest-paid employee, since LEAD() cannot fetch the next row, the difference will be NULL. 3. Highlight Top Earners Using a CASE statement, we check if the employee has the highest salary in their department (SalaryRank = 1). If so, mark as \u0026ldquo;Yes\u0026rdquo;, otherwise \u0026ldquo;No\u0026rdquo;:\nCASE WHEN RANK() OVER (PARTITION BY DivisionID ORDER BY Salary DESC) = 1 THEN \u0026#39;Yes\u0026#39; ELSE \u0026#39;No\u0026#39; END AS IsTopEarner # or CASE WHEN ROW_NUMBER() OVER (PARTITION BY DivisionID ORDER BY Salary DESC) = 1 THEN \u0026#39;Yes\u0026#39; ELSE \u0026#39;No\u0026#39; END AS IsTopEarner Expected Results # The query results will be:\nDivisionID Name Salary SalaryRank SalaryDifference IsTopEarner 100 Lisa Roberts 80000.00 1 40000.00 Yes 100 Daniel Smith 40000.00 2 No 101 Arnold Sully 60000.00 1 Yes 102 Mark Red 86000.00 1 Yes 103 Dennis Front 90000.00 1 Yes 104 Larry Weis 75000.00 1 Yes 105 Susan Wall 110000.00 1 34000.00 Yes 105 Robert Night 76000.00 2 11000.00 No 105 Mary Dial 65000.00 3 No Key Takeaways # Powerful Window Functions Window functions like RANK(), ROW_NUMBER(), and LEAD() are very effective when performing calculations within groups of data. Modular Query Writing Breaking down the task into smaller parts (such as ranking, calculating differences, and conditional logic) helps simplify the problem-solving process and ensures the query’s clarity and maintainability. Efficient Debugging Testing individual parts of the query (such as first checking the output of RANK(), then adding the LEAD() calculation) can speed up the debugging process. Conclusion # This challenge was a great practice to help me apply SQL window functions to solve a real-world problem. From ranking salaries to comparing adjacent row values, and identifying top earners, this query demonstrates how window functions can simplify complex tasks into concise solutions. If you are facing similar challenges, mastering these window functions will greatly improve your SQL skills and data analysis abilities. I’ve written an in-depth article on window functions, feel free to read and share your thoughts!\n","date":"13 January 2025","externalUrl":null,"permalink":"/tech/sql/","section":"TECHNOLOGY","summary":"Recently, I encountered an interesting SQL challenge. The task required using window functions to analyze employee salaries within departments. This is a powerful yet sometimes tricky feature in SQL.\nHere is the problem description and how I solved it.","title":"A SQL Practical Challenge on Salary Analysis","type":"tech"},{"content":" Why Rebuild # Recently, I’ve been preparing for the AWS SAA exam and learning new technologies through side projects. I want to document this journey. Since all the previous blog files were on an old computer in China and the GitHub repository only had public content, I decided to restart my blog as a way to practice writing and keep records.\nTo avoid falling into the same trap again, this time I want a solution that meets the following requirements:\nSupports markdown and ensures easy migration in the future Allows for service hosting Full control over source files and site files The framework must have strong community support No data loss due to switching computers The Hugo + GitHub Pages solution better meets my needs, and I will continue to deploy using Notion + GitHub Actions in the future.\nLocal Setup # Let\u0026rsquo;s start the journey with Hugo. The official documentation is very detailed, and the following is just a personal record.\n1. Hugo Environment # The installation is very simple. I’m using macOS with Homebrew.\n# Open Terminal $brew install hugo Once complete, you can verify the installation with the following command:\n$hugo version 2. Git Environment # The installation is equally simple.\n$brew install git # Similarly, verify the installation with the following command $git version 3. Create a Site # To create a new web site, you can execute the following command:\n$hugo new site my-site # replace \u0026#39;my-site\u0026#39; with your custom blog name, e.g., YuzhenBlog Hugo will generate a custom site in the current directory.\nAt this point, the site has been created.\nThe structure is as follows: my-site/ ├── archetypes/ │ └── default.md ├── assets/ # Stores files processed by Hugo Pipes ├── content/ # Stores markdown files as blog content ├── data/ # Stores data processed by Hugo ├── i18n/ ├── layouts/ # Stores layout files ├── static/ # Stores static files like images, CSS, and JS files ├── themes/ # Stores different themes └── hugo.toml \u0026lt;\u0026ndash; site configuration For detailed explanation, please refer to Directory structure\n4. Configuring the Blowfish Theme # Refer to the theme documentation\n4.1 Download the Blowfish Theme\nThere are several ways to install the Blowfish theme in your Hugo site.\nManual File Copy Install Using Git Submodule (Recommended) If you\u0026rsquo;re unsure which one to choose, go with the Git submodule method. Let\u0026rsquo;s start with the manual method that doesn\u0026rsquo;t require a Git environment locally.\nManual File Copy\nDownload the latest theme source code. Download from GitHub Unzip it, rename the folder to blowfish, and move it to the themes/ directory under your Hugo project root. Then modify hugo.toml Install Using Git Submodule\nThis method ensures that the theme is installed and updated simply and quickly. Besides Hugo, you also need to ensure that Git is installed on your local machine.\nNavigate to the site directory you just created my-site, initialize a new git repository, and add Blowfish as a submodule.\n$cd my-site $git init $git submodule add -b main https://github.com/nunocoracao/blowfish.git themes/blowfish Then modify hugo.toml\nInstall Using Hugo Module This is not covered in this article, but you can refer to the link for more information. 4.2 Next, add theme = \u0026quot;blowfish\u0026quot; in the hugo.toml file. Then start the service as follows\n$hugo server # Start the service and follow the prompt to open the site preview At this point, the Blowfish theme has been successfully configured.\n4.3 exampleSite\nYou might wonder why the page looks different from the theme. That\u0026rsquo;s because other background images, site logos, styles, and content have not yet been added. The simplest way to get started is to copy all files from my-site/themes/blowfish/exampleSite to the site root directory, which is my-site/. Restart the service to get the following preview, and you can start your customization journey.\nreference\nHugo Documentation https://gohugo.io/documentation/\nBlowfish https://blowfish.page/\n","date":"27 August 2024","externalUrl":null,"permalink":"/tech/install-hugo-git/","section":"TECHNOLOGY","summary":"Why Rebuild # Recently, I’ve been preparing for the AWS SAA exam and learning new technologies through side projects. I want to document this journey. Since all the previous blog files were on an old computer in China and the GitHub repository only had public content, I decided to restart my blog as a way to practice writing and keep records.","title":"Build a Personal Blog—1. Install Hugo, Git, Configure the Blowfish Theme","type":"tech"},{"content":" 1. Site Configuration # After copying the exampleSite folder, the site directory structure becomes as follows: my-site/ ├── archetypes/ │ └── default.md ├── assets/ # Stores files processed by Hugo Pipes ├── config/ # Stores config files by Blowfish ├── content/ # Stores markdown files as blog content ├── data/ # Stores data processed by Hugo ├── i18n/ ├── layouts/ # Stores layout files ├── static/ # Stores static files like images, CSS, and JS files ├── themes/ # Stores different themes └── hugo.toml \u0026lt;\u0026ndash; site configuration Site configuration # Compared to before, the config folder is added, which contains default configuration files:\nconfig/_default/ ├─ hugo.toml ├─ languages.en.toml ├─ markup.toml ├─ menus.en.toml ├─ module.toml └─ params.toml The site configuration is managed through the config/_default/hugo.toml file. The table below outlines all the settings that the Blowfish takes advantage of.\nNote that the variable names provided in this table use dot notation to simplify the TOML data structure (ie. outputs.home refers to [outputs] home).\nName Default Description My Value theme \u0026ldquo;blowfish\u0026rdquo; When using Hugo Modules this config value should be removed. For all other installation types, this must be set to blowfish for the theme to function. baseURL Not set The URL to the root of the website. https://yuzhencode.github.io/ To make Blowfish more flexible, each site needs to create at least one language configuration file. By default, Blowfish provides an config/_default/languages.en.toml file for English support.\nGlobal# # Name Default Description My Value title \u0026ldquo;Blowfish\u0026rdquo; The title of the website. This will be displayed in the site header and footer. Yuzhen Blog Params# # Name Default Description My Value params.logo Not set The relative path to the site logo file within the assets/ folder. The logo file should be provided at 2x resolution and supports any image dimensions. img/your site logo.png params.description Not set The website description. This will be used in the site metadata. Author# # Name Default Description My Value params.author.name Not set The author’s name. This will be displayed in article footers, and on the homepage when the profile layout is used. Yuzhen params.author.image Not set Path to the image file of the author. The image should be a 1:1 aspect ratio. The image can be placed in the site’s assets/ folder or can be external url. img/author picture.jpeg params.author.bio Not set A Markdown string containing the author’s bio. It will be displayed in article footers. customisation params.author.links Not set The links to display alongside the author’s details. The config file contains example links which can simply be uncommented to enable. The order that the links are displayed is determined by the order they appear in the array. Custom links can be added by providing corresponding SVG icon assets in assets/icons/. customisation For more details, refer to the Blowfish official documentation.\n2. Generate Favicons for Multiple Browsers and Platforms at Once # Each platform has different icon design requirements, so the same image cannot be used everywhere. First, select your own icon image and then use the RealFaviconGenerator website to generate icons for different platforms.\nYou may need icons in the following formats:\napple-touch-icon.png (180x180) favicon-32x32.png (32x32) favicon-16x16.png (16x16) mstile-150x150.png (150x150) android-chrome-192x192.png (192x192) android-chrome-512x512.png (512x512) favicon.ico browserconfig.xml site.webmanifest Place the generated images and code in the /static directory of your blog\u0026rsquo;s root directory. You can preview the effect locally using hugo server. After deploying to GitHub Pages, it may take some time to take effect. 3. Setting up Menus # Blowfish provides two menus: the main menu is displayed in the site header, and the footer menu is displayed at the bottom of the page. The configuration files are located in menus.en.toml, and if using multilingual features, the file should be renamed according to the corresponding language code.\nExample configuration: # # config/_default/menus.toml [[main]] name = \u0026#34;ABOUT ME\u0026#34; pageRef = \u0026#34;docs/about-me\u0026#34; weight = 10 [[main]] name = \u0026#34;PROJECTS\u0026#34; pageRef = \u0026#34;projects\u0026#34; weight = 20 [[main]] name = \u0026#34;POSTS\u0026#34; weight = 30 [[main]] name = \u0026#34;TECH\u0026#34; parent = \u0026#34;POSTS\u0026#34; pageRef = \u0026#34;tech\u0026#34; weight = 40 [[main]] name = \u0026#34;LIFE\u0026#34; parent = \u0026#34;POSTS\u0026#34; pageRef = \u0026#34;life\u0026#34; weight = 50 [[main]] identifier = \u0026#34;github\u0026#34; pre = \u0026#34;github\u0026#34; url = \u0026#34;https://github.com/yuzhencode\u0026#34; weight = 400 [[footer]] name = \u0026#34;Tags\u0026#34; pageRef = \u0026#34;tags\u0026#34; weight = 10 [[footer]] name = \u0026#34;Authors\u0026#34; pageRef = \u0026#34;authors\u0026#34; weight = 20 4. Theme Parameters # Blowfish offers a variety of parameters to control the theme\u0026rsquo;s features. These parameters are located in the config/_default/params.toml file.\nGlobal # Name Default Description colorScheme \u0026quot;blowfish\u0026quot; The theme colour scheme to use. Valid values are blowfish (default), avocado, fire, ocean, forest, princess, neon, bloody, terminal, marvel, noir, autumn, congo, andslate. Refer to the Colour Schemes section for more details. defaultAppearance \u0026quot;light\u0026quot; The default theme appearance, either light or dark. enableSearch false Whether site search is enabled. Header # Name Default Description header.layout \u0026quot;basic\u0026quot; Defines the header for the entire site, supported values are basic, fixed, fixed-fill, and fixed-fill-blur. Footer # Name Default Description footer.showMenu true Show/hide the footer menu footer.showScrollToTop true When set to true the scroll to top arrow is displayed. Homepage # Name Default Description homepage.layout \u0026quot;profile\u0026quot; The layout of the homepage. homepage.showRecent false Whether or not to display the recent articles list on the homepage. Article # Name Default Description article.showDate true Whether or not article dates are displayed. article.showLikes false Whether or not article likes are displayed. This requires firebase integrations to be enabled For more parameter details, please refer to the Blowfish configuration documentation.\n5. Creating a New Blog Post # From exampleSite we can see that Blowfish has given a template article, for a preview click link. Copy the exampleSite/content/guides/template folder to my-site/archetypes/ and rename it to \u0026lsquo;deault\u0026rsquo;, meanwhile you can change the template file according to your needs.\nYou can create a new blog post using the following command:\n$hugo new tech/test Content dir \u0026#34;yuzhenblog-source/yuzhen/content/tech/test\u0026#34; created You might encounter errors related to multi-language settings when creating a folder. Removing the index.it.md and index.ja.md files should resolve the issue. For more discussion, see Hugo Issue 9204. If you have a better solution, please let me know, here is the error message.\npanic: [BUG] no Page found for \u0026#34;yuzhenblog-source/yuzhen/content/tech/test/index.it.md\u0026#34; goroutine 1 [running]: github.com/gohugoio/hugo/create.(*contentBuilder).applyArcheType(0x140009d4a80, {0x14000d139d0, 0x65}, {0x1066a06e0, 0x14000ad9b40}) github.com/gohugoio/hugo/create/content.go:273 +0x2b8 github.com/gohugoio/hugo/create.(*contentBuilder).buildDir(0x140009d4a80) github.com/gohugoio/hugo/create/content.go:179 +0x51c github.com/gohugoio/hugo/create.NewContent.func1() github.com/gohugoio/hugo/create/content.go:92 +0x268 github.com/gohugoio/hugo/create.NewContent(0x14000b608c0, {0x0, 0x0}, {0x16d33ba21, 0x9}, 0x0) github.com/gohugoio/hugo/create/content.go:106 +0x480 github.com/gohugoio/hugo/commands.newNewCommand.func1({0x0?, 0x0?}, 0x0?, 0x140008ad040, {0x140009b0170, 0x0?, 0x0?}) github.com/gohugoio/hugo/commands/new.go:60 +0x160 github.com/gohugoio/hugo/commands.(*simpleCommand).Run(0x0?, {0x1066956a8?, 0x107ad9600?}, 0x0?, {0x140009b0170?, 0x141f8f4500000000?, 0x1400087f9f8?}) github.com/gohugoio/hugo/commands/commandeer.go:608 +0x48 github.com/bep/simplecobra.(*Commandeer).compile.func1(0x140005e5900?, {0x140009b0170?, 0x4?, 0x10483e075?}) github.com/bep/simplecobra@v0.4.0/simplecobra.go:113 +0x54 github.com/spf13/cobra.(*Command).execute(0x1400098b208, {0x140009b0130, 0x1, 0x1}) github.com/spf13/cobra@v1.8.0/command.go:983 +0x840 github.com/spf13/cobra.(*Command).ExecuteC(0x14000537508) github.com/spf13/cobra@v1.8.0/command.go:1115 +0x344 github.com/spf13/cobra.(*Command).ExecuteContextC(...) github.com/spf13/cobra@v1.8.0/command.go:1048 github.com/bep/simplecobra.(*Exec).Execute(0x14000376cc0, {0x1066956a8?, 0x107ad9600?}, {0x14000333a80?, 0x106226f80?, 0x102b10a9c?}) github.com/bep/simplecobra@v0.4.0/simplecobra.go:155 +0xb4 github.com/gohugoio/hugo/commands.Execute({0x1400011a490, 0x2, 0x2}) github.com/gohugoio/hugo/commands/commandeer.go:67 +0x284 main.main() github.com/gohugoio/hugo/main.go:25 +0x70 A website with a personal touch has been created, and the next post will explain how to publish a blog using GitHub Pages!\n","date":"20 September 2024","externalUrl":null,"permalink":"/tech/custom-theme/","section":"TECHNOLOGY","summary":"1. Site Configuration # After copying the exampleSite folder, the site directory structure becomes as follows: my-site/ ├── archetypes/ │ └── default.md ├── assets/","title":"Build a Personal Blog—2. Customizing the Blowfish Theme","type":"tech"},{"content":"We aim to host the static website generated by Hugo using GitHub Pages service, which allows us to avoid maintaining our own server and ensures more stability and security. Therefore, we need to upload the static web files generated by Hugo to the GitHub Pages repository.\n1. Prepare the GitHub Repository # After logging in, click the top right corner to open the drop-down menu, then click on \u0026ldquo;Your repositories\u0026rdquo; to access the page.\nClick on \u0026ldquo;New\u0026rdquo;\nOn the \u0026ldquo;Create a new repository\u0026rdquo; page:\nCreate two new repositories: one named username.github.io to host the public site, where username is your GitHub username. Additionally, create another private repository named my_site_source as a backup. Normally, only one repository is needed, but my_site_source can store the original files for disaster recovery.\nFor example, if your GitHub username is \u0026ldquo;yuzhencode\u0026rdquo;, the repository name will be yuzhencode.github.io.\nWhen initializing the repository, check the option Initialize this repository with a README to facilitate code pushes later.\n2. Generate Hugo Static Website Locally # Ensure that your hugo.toml or configuration file has the correct baseURL, for example: baseURL = \u0026#34;https://username.github.io/\u0026#34; # Replace username with your GitHub username. Generate static files: Open your blog project directory and run the following command to generate the static files: $hugo The generated static files will be located in the public/ folder of your project. 3. Upload the Generated Files to GitHub Repository # Initialize Git: Enter the public/ folder where the static files were generated and run: $cd public $git init Add GitHub Repository as Remote: Add the GitHub repository as a remote origin: $git remote add origin https://github.com/yuzhencode/yuzhencode.github.io.git # Link the local directory to the remote repository. Add the content in public/ Directory to Git: $git add . $git commit -m \u0026#34;Initial commit - Hugo static files\u0026#34; Push to GitHub: Push the files from public/ to your GitHub repository: $git branch -M main $git push -u origin main 4. Configure GitHub Pages # Enable GitHub Pages: In the Settings tab of your GitHub project, find Pages in the left-hand menu. Under Source, select the main branch and specify /(root) as the publishing directory. After saving these settings, GitHub will start building and hosting your Hugo blog. Access Your Blog: Once GitHub Pages deployment is complete, you can access your blog at https://your-username.github.io/. 5. Local Updates and Deployment # After making updates in Hugo, regenerate the public/ files and repeat the steps in section 4 to push updates:\n$hugo $cd public $git add . $git commit -m \u0026#34;Update site\u0026#34; $git push -u origin main This keeps your Hugo static website synchronized and successfully deployed on GitHub Pages.\n6. Disaster Recovery Backup # For disaster recovery, follow similar commands as in section 3, but do this in the my_site_source directory.\nInitialize Git: Run: $git init Add GitHub Repository as Remote: $git remote add origin https://github.com/yuzhencode/yuzhenblog-source.git # Link the local directory to the remote repository. Add files and push to the GitHub repository: $git add . $git commit -m \u0026#34;Initial commit - Hugo source files\u0026#34; $git push -u origin main Afterward, regularly update the repository with: $git add . $git commit -m \u0026#34;Update site\u0026#34; $git push -u origin main This document explains how to set up a Hugo-generated blog and deploy it on GitHub Pages, with provisions for both production hosting and disaster recovery backups.\n","date":"23 September 2024","externalUrl":null,"permalink":"/tech/deploy-github-pages/","section":"TECHNOLOGY","summary":"We aim to host the static website generated by Hugo using GitHub Pages service, which allows us to avoid maintaining our own server and ensures more stability and security. Therefore, we need to upload the static web files generated by Hugo to the GitHub Pages repository.","title":"Build a Personal Blog—3. Deploying with GitHub Pages","type":"tech"},{"content":"Deploying a personal blog on GitHub Pages has been up and running for some time now, and I have been using the default domain username.github.io. Recently, I finally purchased a 10-year domain on Tencent Cloud for less than 10 pounds. After searching online for articles about custom domains on GitHub, I found the process to be quite simple and can be completed in just a few steps.\nFirst, Register a Domain # There are many domain registrars available online, such as GoDaddy and Namecheap. Many cloud service providers and CDN providers also offer this service, including AWS, GCP, Tencent Cloud, and Cloudflare. This article will provide a detailed explanation based on Tencent Cloud.\nReal-name Verification\nLog in to https://cloud.tencent.com/, go to Console - Domain Registration - Information Template - New Template, and submit it. The review will be completed in about 10 minutes.\nDomain Registration Purchase\nIn the Console - Domain Registration - Overview, enter your desired domain for inquiry, or select a recommended domain and purchase it according to the prompts. After completing this step, you can check Console - Domain Registration - My Domains to see the domain record.\nNext, Add a CNAME File in the Repository # You can choose either of the following operations to bind your domain:\nOption 1: Directly add a CNAME file and enter the domain you want to bind. The file should contain only the main domain you want to bind, without including http:// and www.\nOption 2: Click on your blog repository, go to Settings, find Custom domain, and add your domain before saving it.\nFinally, Add A Records to Point to GitHub Blog IP Address # Open the terminal and use ping on your GitHub blog address username.github.io to obtain an IP address.\nIn My Domains - DNS Settings, add two A records. The record values should be the IP address obtained from the previous step. Set one host record as “www” and the other as “@”. This way, you can access your blog via both yourblog.com and www.yourblog.com. Please wait for the DNS configuration to take effect, which typically completes within 10 minutes.\nAdditional Tips # HTTPS Configuration: Once the domain is successfully bound, remember to enable HTTPS in the GitHub Pages settings to ensure the security of your site. Regularly Check DNS Records: If you find that your site is inaccessible, you can check the DNS settings to ensure there are no errors. Blog Content Management: Regularly update your blog content to stay active and increase visitor return rates. By following these steps, you can successfully bind your domain to GitHub Pages, enhancing the professionalism and accessibility of your personal blog. If you have any further questions or need additional assistance, feel free to contact me!\n","date":"7 October 2024","externalUrl":null,"permalink":"/tech/custom-domain/","section":"TECHNOLOGY","summary":"Deploying a personal blog on GitHub Pages has been up and running for some time now, and I have been using the default domain username.github.io. Recently, I finally purchased a 10-year domain on Tencent Cloud for less than 10 pounds.","title":"Build a Personal Blog—4. How to Bind a Custom Domain to Your GitHub Pages Blog","type":"tech"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/data-analysis/","section":"Tags","summary":"","title":"Data Analysis","type":"tags"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/data-assessment/","section":"Tags","summary":"","title":"Data Assessment","type":"tags"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/mysql/","section":"Tags","summary":"","title":"MySQL","type":"tags"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/salary-analysis/","section":"Tags","summary":"","title":"Salary Analysis","type":"tags"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/salary-difference/","section":"Tags","summary":"","title":"Salary Difference","type":"tags"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/series/sql/","section":"Series","summary":"","title":"SQL","type":"series"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/sql/","section":"Tags","summary":"","title":"SQL","type":"tags"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/sql-queries/","section":"Tags","summary":"","title":"SQL Queries","type":"tags"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/sql-ranking/","section":"Tags","summary":"","title":"SQL Ranking","type":"tags"},{"content":"","date":"2025-01-13","externalUrl":null,"permalink":"/zh-cn/tags/sql-%E6%8E%92%E5%90%8D/","section":"标签","summary":"","title":"SQL 排名","type":"tags"},{"content":"","date":"2025-01-13","externalUrl":null,"permalink":"/zh-cn/tags/sql-%E6%9F%A5%E8%AF%A2/","section":"标签","summary":"","title":"SQL 查询","type":"tags"},{"content":"Blowfish has full support for Hugo taxonomies and will adapt to any taxonomy set up. Taxonomy listings like this one also support custom content to be displayed above the list of terms.\nThis area could be used to add some extra descriptive text to each taxonomy. Check out the advanced tag below to see how to take this concept even further.\n","date":"13 January 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"Blowfish has full support for Hugo taxonomies and will adapt to any taxonomy set up. Taxonomy listings like this one also support custom content to be displayed above the list of terms.","title":"Tags","type":"tags"},{"content":" Love to share ","date":"13 January 2025","externalUrl":null,"permalink":"/tech/","section":"TECHNOLOGY","summary":" Love to share ","title":"TECHNOLOGY","type":"tech"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/top-earners/","section":"Tags","summary":"","title":"Top Earners","type":"tags"},{"content":" A software \u0026amp; data engineer by day, Zhou Shen fan and panda lover by night! Chasing Life\u0026rsquo;s Little Adventure! 🏋️\u0026amp;⛰️\u0026amp;🍄 Hi, I recently completed my Master of Science in Computer Science with distinction. Over the past several years, I\u0026rsquo;ve gained significant experience as a Software Engineer. My expertise lies in software development, data analytics, and machine learning, with hands-on experience in technologies like Java, Python, and cloud services such as AWS.\nOne of my key projects involved innovated a patent which is a automate data collection system (across multiple databases) that dramatically improved efficiency, reducing manual labor by 90% and increasing data extraction rates from under 10% to over 80%.\nSeptember 05, 2024: AWS Certified Solutions Architect – Associate ","date":"13 January 2025","externalUrl":null,"permalink":"/","section":"Welcome to the Yuzhen(Lee)'s Blog","summary":"A software \u0026amp; data engineer by day, Zhou Shen fan and panda lover by night! Chasing Life\u0026rsquo;s Little Adventure! 🏋️\u0026amp;⛰️\u0026amp;🍄 Hi, I recently completed my Master of Science in Computer Science with distinction.","title":"Welcome to the Yuzhen(Lee)'s Blog","type":"page"},{"content":"","date":"13 January 2025","externalUrl":null,"permalink":"/tags/window-functions/","section":"Tags","summary":"","title":"Window Functions","type":"tags"},{"content":"","date":"2025-01-13","externalUrl":null,"permalink":"/zh-cn/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/","section":"标签","summary":"","title":"数据分析","type":"tags"},{"content":"","date":"2025-01-13","externalUrl":null,"permalink":"/zh-cn/tags/%E6%95%B0%E6%8D%AE%E8%AF%84%E4%BC%B0/","section":"标签","summary":"","title":"数据评估","type":"tags"},{"content":"","date":"2025-01-13","externalUrl":null,"permalink":"/zh-cn/tags/%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0/","section":"标签","summary":"","title":"窗口函数","type":"tags"},{"content":"","date":"2025-01-13","externalUrl":null,"permalink":"/zh-cn/tags/%E8%96%AA%E8%B5%84%E5%88%86%E6%9E%90/","section":"标签","summary":"","title":"薪资分析","type":"tags"},{"content":"","date":"2025-01-13","externalUrl":null,"permalink":"/zh-cn/tags/%E8%96%AA%E8%B5%84%E5%B7%AE%E5%BC%82/","section":"标签","summary":"","title":"薪资差异","type":"tags"},{"content":"","date":"2025-01-13","externalUrl":null,"permalink":"/zh-cn/tags/%E9%AB%98%E8%96%AA%E5%91%98%E5%B7%A5/","section":"标签","summary":"","title":"高薪员工","type":"tags"},{"content":"","date":"9 October 2024","externalUrl":null,"permalink":"/tags/automation/","section":"Tags","summary":"","title":"Automation","type":"tags"},{"content":"","date":"9 October 2024","externalUrl":null,"permalink":"/tags/data-engineering/","section":"Tags","summary":"","title":"Data Engineering","type":"tags"},{"content":"","date":"9 October 2024","externalUrl":null,"permalink":"/tags/etl/","section":"Tags","summary":"","title":"ETL","type":"tags"},{"content":"With the growth of enterprise data, managing and integrating multiple databases has become a significant challenge. Patent CN111339081A , titled \u0026ldquo;Automatic collection method and system for table directory of heterogeneous database\u0026rdquo;, offers a highly automated solution that boosts data extraction efficiency by up to 70% and reduces manual deployment and verification time by 90%. This innovation dramatically enhances the efficiency of ETL (Extract, Transform, Load) processes, while intelligent automated monitoring simplifies the entire data integration and validation workflow.\nPatent Background # In modern enterprises, data is often scattered across various database systems. Differences in data structures and formats make the process of collecting and integrating information cumbersome and time-consuming. This patent proposes an automated approach to efficiently collecting table directory information from various database systems, significantly streamlining the data extraction and analysis process.\nPatent Overview # Patent CN111339081A describes an automated system for efficiently gathering basic information from heterogeneous databases. The key steps of this system include:\nData Collection: The system automatically collects basic information from various databases, generating an initial list of database tables. Data Analysis: Collected information is analyzed to identify relationships between data. Monitoring Data Quality Metrics: Real-time monitoring of data quality metrics ensures the reliability of data analysis by quickly responding to potential issues. Data Tools: Tools like Pentaho-Kettle and Python are used to extract, transform, and load data into a data warehouse for business use. Predictive Modeling: The system uses Python-based algorithms to optimize the order of data extraction, improving efficiency. CI/CD Pipelines: Jenkins is used to automate testing and deployment of the data pipeline, streamlining development. Backup and Recovery: Automated backup and recovery processes ensure data security and availability, preventing data loss. Key Advantages # Efficiency Gains: Automated data collection significantly improves data management across various database environments, reducing manual intervention. Enhanced Management: The system provides a structured view of database storage, enabling businesses to better understand and optimize data processing. Optimization Suggestions # Through continued learning and project practice, I’ve identified several areas for further optimization in real-world production environments.\n1. Data Architecture Design # Combining Data Lakes with Data Warehouses: A hybrid architecture that integrates data lakes (e.g., AWS S3、Azure Data Lake Storage、GCP Cloud Storage ) with data warehouses (e.g., Redshift、Azure Synapse、BigQuery ) would offer several benefits:\nFlexibility: Data lakes support multiple formats (structured, semi-structured, and unstructured), giving enterprises flexibility to process various data types. Data warehouses focus on high-performance querying, suitable for business analytics. Cost Efficiency: Storing large amounts of raw data in a data lake reduces storage costs. High-frequency, low-latency analyses can be performed in a data warehouse for better performance. Data Integration: A data lake enables centralized storage of data from multiple sources (e.g., IoT devices, social media, log files), providing a unified source for downstream analysis. Real-Time Analytics: By combining data lakes and warehouses, enterprises can perform real-time data processing. Streaming data in a data lake can be analyzed in real-time through the data warehouse. Data Governance and Compliance: This architecture improves lifecycle management of data, ensuring security and compliance, while offering access control and auditing features. Enhanced Data Science: A data lake stores vast amounts of historical data, ideal for machine learning and deep learning models, while the data warehouse supports efficient analytics. By combining a data lake and warehouse architecture, businesses can better adapt to evolving data needs and improve management flexibility.\n2. Optimizing ETL/ELT Processes # Use Modern ETL Tools: Leveraging modern tools like Apache Airflow、DBT for managing and monitoring data pipelines ensures transparency and traceability.\nTask Scheduling with Apache Airflow: Instead of relying on traditional Linux cron jobs, Apache Airflow offers:\nVisualization and Monitoring: Modern ETL tools provide user-friendly interfaces that allow teams to visualize data flows and task statuses, improving pipeline management. Dependency Management: Airflow supports complex task dependencies, ensuring that tasks execute in the correct order—essential for intricate ETL processes. Retry Mechanisms: Built-in retry functionality in Airflow ensures that tasks automatically rerun upon failure, improving reliability. Flexibility and Scalability: Airflow allows users to define data pipelines via code, enabling version control and rapid iteration. It also supports integration with a variety of data sources and targets. Dynamic Scheduling: Airflow supports conditional task generation, enabling pipelines to adjust dynamically based on changes in the data, offering more processing flexibility. Open Source and Community Support: As an open-source project, Airflow benefits from a large community, continuous updates, and customization options. Advantages of DBT:\nData Modeling and Transformation: DBT focuses on data transformation, providing simple SQL syntax to enable teams to easily write and manage data models. Version Control: DBT allows the transformation process to be versioned, enabling teams to track changes and ensure transparency and traceability. Automated Documentation: DBT automatically generates data documentation, creating clear data dictionaries that aid in governance and compliance. Using modern ETL tools can significantly enhance pipeline management, ensuring transparency, traceability, and reliability, laying a solid foundation for subsequent data analysis.\n3. Data Quality Management # Implement Data Validation: Tools like Great Expectations can automate data quality checks, reducing manual intervention and improving efficiency. Metadata Management: Establish a metadata management system to track data origins, changes, and usage, helping teams understand data context and business significance. 4. Containerization # Using Docker and Kubernetes: Containerize data processing and ETL workflows using Docker to create lightweight, portable containers, ensuring consistency across environments. Use Kubernetes for container orchestration, supporting autoscaling and high availability. Environment Consistency: Containerization eliminates the \u0026ldquo;works on my machine\u0026rdquo; problem, ensuring consistency between development, testing, and production environments, reducing configuration errors. Simplified Dependency Management: Applications and their dependencies are bundled together, simplifying deployment, version management, and rapid iteration. 5. Monitoring and Performance Optimization # Real-Time Monitoring: Use tools like Prometheus and Grafana to monitor data pipelines and database performance in real-time, quickly identifying and resolving issues. Performance Tuning: Regularly evaluate query performance using database analysis tools (e.g., EXPLAIN statements), optimizing indexes and query logic to enhance performance. Conclusion # Contributing to the development of this patent has deepened my understanding of managing heterogeneous relational databases and enhanced my technical capabilities. I believe that as data management technologies continue to evolve, innovations like this will become increasingly critical, providing more convenience for enterprise data processing.\n","date":"9 October 2024","externalUrl":null,"permalink":"/projects/patent-cn111339081a-database-automation/","section":"PROJECTS","summary":"With the growth of enterprise data, managing and integrating multiple databases has become a significant challenge. Patent CN111339081A , titled \u0026ldquo;Automatic collection method and system for table directory of heterogeneous database\u0026rdquo;, offers a highly automated solution that boosts data extraction efficiency by up to 70% and reduces manual deployment and verification time by 90%.","title":"How to Automatically Collect Heterogeneous Database Table Directories | Analysis of Patent CN111339081A","type":"projects"},{"content":"","date":"9 October 2024","externalUrl":null,"permalink":"/tags/patent/","section":"Tags","summary":"","title":"Patent","type":"tags"},{"content":" Show projects developed by me. Will be updated\u0026hellip; ","date":"9 October 2024","externalUrl":null,"permalink":"/projects/","section":"PROJECTS","summary":" Show projects developed by me. Will be updated\u0026hellip; ","title":"PROJECTS","type":"projects"},{"content":"","date":"2024-10-09","externalUrl":null,"permalink":"/zh-cn/tags/%E4%B8%93%E5%88%A9/","section":"标签","summary":"","title":"专利","type":"tags"},{"content":"","date":"2024-10-09","externalUrl":null,"permalink":"/zh-cn/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/","section":"标签","summary":"","title":"数据工程","type":"tags"},{"content":"","date":"7 October 2024","externalUrl":null,"permalink":"/tags/blog-setup/","section":"Tags","summary":"","title":"Blog Setup","type":"tags"},{"content":"","date":"7 October 2024","externalUrl":null,"permalink":"/tags/custom-domain/","section":"Tags","summary":"","title":"Custom Domain","type":"tags"},{"content":"","date":"7 October 2024","externalUrl":null,"permalink":"/tags/documentation/","section":"Tags","summary":"","title":"Documentation","type":"tags"},{"content":"","date":"7 October 2024","externalUrl":null,"permalink":"/tags/github-pages/","section":"Tags","summary":"","title":"GitHub Pages","type":"tags"},{"content":"","date":"7 October 2024","externalUrl":null,"permalink":"/series/personal-blog-documentation/","section":"Series","summary":"","title":"Personal Blog Documentation","type":"series"},{"content":"","date":"7 October 2024","externalUrl":null,"permalink":"/tags/seo/","section":"Tags","summary":"","title":"SEO","type":"tags"},{"content":"","date":"2024-10-07","externalUrl":null,"permalink":"/zh-cn/series/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2-%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/","section":"Series","summary":"","title":"个人博客 部署教程","type":"series"},{"content":"","date":"2024-10-07","externalUrl":null,"permalink":"/zh-cn/tags/%E5%8D%9A%E5%AE%A2%E8%AE%BE%E7%BD%AE/","section":"标签","summary":"","title":"博客设置","type":"tags"},{"content":"","date":"2024-10-07","externalUrl":null,"permalink":"/zh-cn/tags/%E6%96%87%E6%A1%A3/","section":"标签","summary":"","title":"文档","type":"tags"},{"content":"","date":"2024-10-07","externalUrl":null,"permalink":"/zh-cn/tags/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9F%9F%E5%90%8D/","section":"标签","summary":"","title":"自定义域名","type":"tags"},{"content":" 🍄Fungus found on 05 Oct 2024 # As someone who loves hunting for mushrooms in the wild, I’ve always assumed that my most exciting finds would be deep in the forest, far away from urban life. But my latest discovery came in a completely unexpected place – right by the canal, on the outskirts of the city. And what I found there was none other than the legendary fly agaric.\nA Sea of White Mushrooms… and One Special Find # It all started with a walk along the canal. I wasn’t on the lookout for anything in particular, but then I noticed a large cluster of white mushrooms, growing in tight, dense patches. To be honest, they didn’t really grab my attention straight away – they seemed fairly ordinary, and I was about to carry on walking. But then I spotted one group of mushrooms that looked especially photogenic, so I wandered over, camera in hand.\nAs I got closer, that’s when I noticed it. Nestled amongst the more common white mushrooms was something much more striking – a small, vibrant red mushroom with its cap still in a ball-like shape. It was only just beginning to grow, the veil between the cap and the stem still intact. And it was immediately clear to me that this was something special: a fly agaric (or Amanita muscaria, for the more scientifically minded).\nRecognising a Classic # Now, at the time, I didn’t know for certain that this was a fly agaric, but it looked just like the kind of mushroom you imagine when you think of poisonous fungi – the very definition of the ‘dangerous red mushroom’ emoji 🍄. I couldn’t contain my excitement. Here, in this unassuming spot by the canal, I had stumbled upon one of the most iconic fungi in existence!\nWhat’s interesting about the fly agaric is its instantly recognisable appearance. Typically, it has:\nA bright red cap: often with white or yellowish spots that are remnants of its universal veil. A white stem: which is tall and elegant, often with a skirt-like ring around it. White gills underneath the cap, tightly packed together. White spore print: if you happen to take a spore print. However, the mushroom I found was still young, with its red cap in a spherical stage, yet to open fully. It was fascinating to see it at this early point in its life cycle – something I hadn’t expected to witness up close.\n“Red Cap, White Stem”: A Cultural Icon # In the UK (and many other places), the fly agaric is almost a cultural icon. It’s featured in everything from fairy tales to video games, with its bright red cap and white spots giving it an almost mythical status. But what many people don’t realise is that it’s also highly toxic. There’s even a popular saying in China that sums it up perfectly: “红伞伞，白杆杆”, which translates to “red cap, white stem” – it’s a phrase used to describe dangerous mushrooms like the fly agaric.\nThe fly agaric contains toxins such as ibotenic acid and muscimol, which, when ingested, can cause nausea, vomiting, hallucinations, and confusion. Although it’s not usually fatal, it’s certainly not something you’d want to snack on! Interestingly, in some cultures, such as certain Siberian tribes, fly agarics were used in spiritual rituals for their psychoactive effects. But here in the UK, it’s best admired from a distance.\nA City-Edge Surprise # What made this find even more special was its location. I never expected to come across something as rare as a fly agaric in such an urban setting. It’s a reminder that nature’s surprises aren’t confined to remote forests – they can pop up even in the most unexpected places, like a quiet canal on the edge of a city.\nWhile the cluster of white mushrooms that originally caught my eye might have been more common, this single, striking fly agaric stole the show. It felt almost like nature had placed it there, just for me to discover.\nSafety First: Mushroom Hunting Tips # Of course, while mushroom hunting is a brilliant way to connect with nature, it’s important to remember that safety comes first. If you’re not 100% sure of what you’ve found, it’s always best to leave it where it is. Here are a few tips to keep in mind:\nDon’t eat anything unless you’re absolutely sure what it is. Many mushrooms look alike, and some deadly species closely resemble edible ones. Use a reliable guide or app to help with identification. Admire without touching. Some mushrooms can cause skin irritation or worse, so it\u0026rsquo;s best to avoid handling them unless you\u0026rsquo;re wearing gloves. Wrapping Up # Discovering this fly agaric by the canal was an absolute thrill – a vivid reminder that nature’s wonders can be found in the most unexpected places. Its red cap and white spots were instantly recognisable, and though I was only seeing it in its early stage of growth, it was no less impressive.\nIf you’ve ever come across a similar natural surprise, whether deep in the woods or right on your doorstep, I’d love to hear about it! After all, you never know what magic might be waiting just around the corner.\n“红伞伞，白杆杆”：A Poisonous Mushroom Song # As mentioned earlier, the fly agaric mushroom is vividly captured in a well-known Chinese children’s rhyme. It serves as both a warning and a darkly humorous take on the dangers of eating brightly coloured, unknown mushrooms. Here’s the full version of the rhyme, along with an English translation:\n中文原文： English Translation: 红伞伞，白杆杆 Red cap, white stem 吃完一起躺板板 After eating, you’ll all lie flat 躺板板，埋山山 Lie flat, buried in the hill 亲朋都来吃饭饭 Friends and family come for a meal 饭饭里有红伞伞 In the meal, there\u0026#39;s a red cap 吃完全村都埋山山 Eat it, and the whole village is buried in the hill 来年长满红伞伞 Next year, the hill will be full of red caps ","date":"6 October 2024","externalUrl":null,"permalink":"/life/fungi_05oct2024/","section":"LIFE","summary":"🍄Fungus found on 05 Oct 2024 # As someone who loves hunting for mushrooms in the wild, I’ve always assumed that","title":"🍄An Unexpected Find: Discovering a Fly Agaric by the Canal","type":"life"},{"content":"","date":"6 October 2024","externalUrl":null,"permalink":"/tags/life/","section":"Tags","summary":"","title":"Life","type":"tags"},{"content":" 🏋️\u0026amp;⛰️\u0026amp;🍄 ","date":"6 October 2024","externalUrl":null,"permalink":"/life/","section":"LIFE","summary":" 🏋️\u0026amp;⛰️\u0026amp;🍄 ","title":"LIFE","type":"life"},{"content":"","date":"6 October 2024","externalUrl":null,"permalink":"/tags/mushroom/","section":"Tags","summary":"","title":"Mushroom","type":"tags"},{"content":"","date":"2024-10-06","externalUrl":null,"permalink":"/zh-cn/tags/%E7%94%9F%E6%B4%BB/","section":"标签","summary":"","title":"生活","type":"tags"},{"content":"","date":"2024-10-06","externalUrl":null,"permalink":"/zh-cn/tags/%E8%98%91%E8%8F%87/","section":"标签","summary":"","title":"蘑菇","type":"tags"},{"content":" 1. Fleecyfoot Conecap🍄 # It may be Fleecyfoot Conecap. It contains the psychedelic alkaloids psilocybin and psilocin. https://www.gbif.org/species/2529949\n2. Grey Knight🍄 # It may be Grey Knight - Tricholoma terreum. A 2014 article speculated that it may be poisonous, but Sitta et al. in 2016 published in the same journal a counter article demonstrating the unfounded nature of such speculation. https://www.naturespot.org.uk/species/grey-knight https://en.wikipedia.org/wiki/Tricholoma_terreum\n3. Parasola plicatilis🍄 # It may be Parasola plicatilis. Though nonpoisonous, the species is generally regarded as inedible. https://commons.wikimedia.org/wiki/Parasola_plicatilis https://en.wikipedia.org/wiki/Parasola_plicatilis\nAll 🍄 found at Muntz Park, Gristhorpe Rd, Birmingham B29 7TD\n","date":"24 September 2024","externalUrl":null,"permalink":"/life/fungi_14sep2024/","section":"LIFE","summary":"1. Fleecyfoot Conecap🍄 # It may be Fleecyfoot Conecap. It contains the psychedelic alkaloids psilocybin and psilocin. https://www.gbif.org/species/2529949\n2. Grey Knight🍄 # It may be Grey Knight - Tricholoma terreum.","title":"🍄Fungus found on 14 Sep 2024","type":"life"},{"content":"","date":"24 September 2024","externalUrl":null,"permalink":"/tags/bug/","section":"Tags","summary":"","title":"Bug","type":"tags"},{"content":"","date":"24 September 2024","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":" Problem Description # Recently, I’ve been using GitHub to configure and update my blog. However, today I noticed that my contributions are not being recorded on GitHub, and the commit history in the repository shows the following:\nCause # The Git on my Mac was installed using Homebrew, and I didn’t configure it locally. As a result, when I pushed local files to the repository using the terminal, the default user.name and user.email for Git were from my local machine, not my GitHub account.\n1. Check the commit history # $git log Even though I\u0026rsquo;m pushing to my GitHub repository, the username and email are from my local machine.\n2. Check your local Git configuration # $git config user.name $git config user.email If the result is blank, it means GitHub isn’t tracking the contributions because the commits aren\u0026rsquo;t linked to your GitHub account.\nSolution # 1. Configure Git locally # $git config --global user.name \u0026#34;github accountname\u0026#34; $git config --global user.email \u0026#34;github@xx.com\u0026#34; Here, the --global flag applies the changes to all repositories on your machine. If omitted, the change will apply only to the current repository. Once you configure it correctly, future commits will reflect your GitHub account and will be counted as contributions.\n2. Modify previous commit history # Update the commit history to associate previous commits with your GitHub account.\n# Modify author information for past commits $git filter-branch -f --env-filter \u0026#39; if [ \u0026#34;$GIT_AUTHOR_NAME\u0026#34; = \u0026#34;oldName\u0026#34; ] then export GIT_AUTHOR_NAME=\u0026#34;newName\u0026#34; export GIT_AUTHOR_EMAIL=\u0026#34;newEmail\u0026#34; fi \u0026#39; HEAD # Modify committer information for past commits $git filter-branch -f --env-filter \u0026#39; if [ \u0026#34;$GIT_COMMITTER_NAME\u0026#34; = \u0026#34;oldName\u0026#34; ] then export GIT_COMMITTER_NAME=\u0026#34;newName\u0026#34; export GIT_COMMITTER_EMAIL=\u0026#34;newEmail\u0026#34; fi \u0026#39; HEAD NOTICE\nIf you write your own commit, then both are you.\nSome projects have people who don\u0026rsquo;t have commit access, so you need to give them to someone who has the access to commit after modification, so you are AUTHOR and not COMMITTER!\nIf the modification is successful prompt:Ref ‘refs/heads/master’ was rewritten\nIf the modification fails to prompt: Ref ‘refs/heads/master’ is unchanged here may be because the fill in the oldName is not found.\nIf you want to change it without any difference, remove the if...fi\n$git filter-branch -f --env-filter \u0026#34; GIT_AUTHOR_NAME=\u0026#39;newName\u0026#39;; GIT_AUTHOR_EMAIL=\u0026#39;newEmail\u0026#39;; GIT_COMMITTER_NAME=\u0026#39;newName\u0026#39;; GIT_COMMITTER_EMAIL=\u0026#39;newEmail\u0026#39; \u0026#34; HEAD 3. Push changes to the remote repository # Force push after modifying the commit history $git push -u origin master -f This command forces the changes to the remote repository, overriding existing data. This should be used with caution, especially in collaborative projects.\nPull the latest changes before pushing $git pull origin main $git push -u origin main If you want to avoid merging remote changes, create a new branch $git branch [name] $git push -u origin [name] Once done, your contributions should be successfully updated!🎉\n","date":"24 September 2024","externalUrl":null,"permalink":"/tech/github_contribution_issues/","section":"TECHNOLOGY","summary":"Problem Description # Recently, I’ve been using GitHub to configure and update my blog. However, today I noticed that my contributions are not being recorded on GitHub, and the commit history in the repository shows the following:","title":"Problem solving——Local commits to GitHub repositories, contributions not shown","type":"tech"},{"content":"","date":"24 September 2024","externalUrl":null,"permalink":"/tags/yuzhen/","section":"Tags","summary":"","title":"Yuzhen","type":"tags"},{"content":"","date":"2024-09-24","externalUrl":null,"permalink":"/zh-cn/tags/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","section":"标签","summary":"","title":"问题解决","type":"tags"},{"content":"","date":"23 September 2024","externalUrl":null,"permalink":"/tags/config/","section":"Tags","summary":"","title":"Config","type":"tags"},{"content":"","date":"23 September 2024","externalUrl":null,"permalink":"/tags/docs/","section":"Tags","summary":"","title":"Docs","type":"tags"},{"content":"","date":"2024-09-23","externalUrl":null,"permalink":"/zh-cn/tags/%E9%85%8D%E7%BD%AE/","section":"标签","summary":"","title":"配置","type":"tags"},{"content":" Profile # I graduated as a master student with distinction from the University of Birmingham in Computer Science. I am very fortunate to have been supervised by Dr. Peter Hancox for my thesis on Fine-grained Sentiment Analysis of Yelp-review and Exploring Multi-class Imbalanced Data. Over the past several years, I\u0026rsquo;ve gained significant experience as a Software Engineer. My expertise lies in software development, data analytics, and machine learning, with hands-on experience in technologies like Java, Python, and cloud services such as AWS.\nWhen I am not working, I like to spend time exploring the city and listening to Zhou Shen a Chinese singer. I also run a database query website for him, used by a fan group of around 40 people. This website involves around 160,000 data entries, developed with MySQL database, Python crawler technology, and Flask framework.\nInterests # Software Development Data Science Artificial Intelligence Fitness 🏋️ Exploring nature, including but not limited to: hiking ⛰️, mushroom hunting 🍄 Skills # Programming Languages: Java, Python, SQL Cloud \u0026amp; DevOps: AWS, Docker, Kubernetes, Terraform, Jenkins Databases \u0026amp; Messaging: Redis, Kafka, MongoDB, MySQL, Oracle, PostgreSQL Methodologies \u0026amp; Tools: Agile, CI/CD, Microservices, RESTful APIs Education # MSc Computer Science, 2022 (Distinction)\nUniversity of Birmingham\nBSc Technology \u0026amp; Instrument of Detection \u0026amp; Control, 2017\nShandong University\n","date":"1 January 0001","externalUrl":null,"permalink":"/docs/about-me/","section":"Documentation","summary":"Profile # I graduated as a master student with distinction from the University of Birmingham in Computer Science. I am very fortunate to have been supervised by Dr. Peter Hancox for my thesis on Fine-grained Sentiment Analysis of Yelp-review and Exploring Multi-class Imbalanced Data.","title":"About Me","type":"docs"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/tags/aboutme/","section":"Tags","summary":"","title":"Aboutme","type":"tags"},{"content":"This is the advanced tag. Just like other listing pages in Blowfish, you can add custom content to individual taxonomy terms and it will be displayed at the top of the term listing. \u0026#x1f680;\nYou can also use these content pages to define Hugo metadata like titles and descriptions that will be used for SEO and other purposes.\n","date":"1 January 0001","externalUrl":null,"permalink":"/tags/advanced/","section":"Tags","summary":"This is the advanced tag. Just like other listing pages in Blowfish, you can add custom content to individual taxonomy terms and it will be displayed at the top of the term listing.","title":"Advanced","type":"tags"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":" ","date":"1 January 0001","externalUrl":null,"permalink":"/docs/","section":"Documentation","summary":" ","title":"Documentation","type":"docs"},{"content":"","date":"0001-01-01","externalUrl":null,"permalink":"/zh-cn/tags/%E5%85%B3%E4%BA%8E%E6%88%91/","section":"标签","summary":"","title":"关于我","type":"tags"}]